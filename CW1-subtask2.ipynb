{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blind-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ruled-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ordinary-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Wen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Wen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rough-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset/passage_collection_new.txt\", 'r', encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amazing-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "descending-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"qid\", \"pid\", \"query\", \"passage\"]\n",
    "candidate_passages_top1000 = pd.read_csv(\"dataset/candidate_passages_top1000.tsv\", sep='\\t', names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funny-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"qid\", \"query\"]\n",
    "test_queries = pd.read_csv(\"dataset/test-queries.tsv\", sep='\\t', names=header_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-minister",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-teach",
   "metadata": {},
   "source": [
    "## Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "regulated-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = document.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-allocation",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "commercial-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens = nltk.word_tokenize(document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-diversity",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tropical-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(tokens):\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        new_token = re.sub(r'[^\\w\\s]', '', token)\n",
    "        if new_token != '':\n",
    "            new_tokens.append(new_token)\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "general-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = remove_punctuation(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-tours",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valuable-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    new_tokens = []\n",
    "    stopword_set = set(stopwords.words('english'))\n",
    "    for token in tokens:\n",
    "        if token not in stopword_set:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opposite-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens = remove_stopwords(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-glenn",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "optional-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_verbs(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    root_words = []\n",
    "    for token in tokens:\n",
    "        root_word = lemmatizer.lemmatize(token, pos='v')\n",
    "#         root_word = lemmatizer.lemmatize(token, pos='n')\n",
    "#         root_word = lemmatizer.lemmatize(token, pos='a')\n",
    "        root_words.append(root_word)\n",
    "    return root_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "endangered-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens = lemmatize_verbs(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-calculation",
   "metadata": {},
   "source": [
    "## Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "regional-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(tokens):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isdigit():\n",
    "#             new_token = num2words(int(token), to = 'ordinal')\n",
    "#             new_tokens.append(new_token)\n",
    "            pass\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "excellent-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = remove_numbers(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "vulnerable-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(passage):\n",
    "    passage = passage.lower()\n",
    "    tokens = nltk.word_tokenize(passage)\n",
    "    tokens = remove_punctuation(tokens)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize_verbs(tokens)\n",
    "    tokens = remove_numbers(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-singer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "experienced-geology",
   "metadata": {},
   "source": [
    "# Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-earthquake",
   "metadata": {},
   "source": [
    "## Extracting Pid and Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "soviet-resolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>494835</td>\n",
       "      <td>7130104</td>\n",
       "      <td>sensibilities, definition</td>\n",
       "      <td>This is the definition of RNA along with examp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1128373</td>\n",
       "      <td>7130104</td>\n",
       "      <td>iur definition</td>\n",
       "      <td>This is the definition of RNA along with examp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131843</td>\n",
       "      <td>7130104</td>\n",
       "      <td>definition of a sigmet</td>\n",
       "      <td>This is the definition of RNA along with examp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20455</td>\n",
       "      <td>7130335</td>\n",
       "      <td>ar glasses definition</td>\n",
       "      <td>Best Answer: The AR designation comes from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>719381</td>\n",
       "      <td>7130335</td>\n",
       "      <td>what is ar balance</td>\n",
       "      <td>Best Answer: The AR designation comes from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189872</th>\n",
       "      <td>1056204</td>\n",
       "      <td>79980</td>\n",
       "      <td>who was the first steam boat operator</td>\n",
       "      <td>Other operators with special formats accept mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189873</th>\n",
       "      <td>1132213</td>\n",
       "      <td>7998257</td>\n",
       "      <td>how long to hold bow in yoga</td>\n",
       "      <td>You may be surprised that to learn that yoga t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189874</th>\n",
       "      <td>324211</td>\n",
       "      <td>7998651</td>\n",
       "      <td>how much money a united airline get as a capta...</td>\n",
       "      <td>Find cheap airline tickets &amp; deals on flights ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189875</th>\n",
       "      <td>1116341</td>\n",
       "      <td>7998709</td>\n",
       "      <td>closed ended mortgage definition</td>\n",
       "      <td>What is a wrap-around mortgage, and who is it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189876</th>\n",
       "      <td>1124145</td>\n",
       "      <td>7998901</td>\n",
       "      <td>truncating meaning</td>\n",
       "      <td>Katie The name Katie is a baby girl name. Mean...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189877 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qid      pid                                              query  \\\n",
       "0        494835  7130104                          sensibilities, definition   \n",
       "1       1128373  7130104                                     iur definition   \n",
       "2        131843  7130104                             definition of a sigmet   \n",
       "3         20455  7130335                              ar glasses definition   \n",
       "4        719381  7130335                                 what is ar balance   \n",
       "...         ...      ...                                                ...   \n",
       "189872  1056204    79980              who was the first steam boat operator   \n",
       "189873  1132213  7998257                       how long to hold bow in yoga   \n",
       "189874   324211  7998651  how much money a united airline get as a capta...   \n",
       "189875  1116341  7998709                   closed ended mortgage definition   \n",
       "189876  1124145  7998901                                 truncating meaning   \n",
       "\n",
       "                                                  passage  \n",
       "0       This is the definition of RNA along with examp...  \n",
       "1       This is the definition of RNA along with examp...  \n",
       "2       This is the definition of RNA along with examp...  \n",
       "3       Best Answer: The AR designation comes from the...  \n",
       "4       Best Answer: The AR designation comes from the...  \n",
       "...                                                   ...  \n",
       "189872  Other operators with special formats accept mo...  \n",
       "189873  You may be surprised that to learn that yoga t...  \n",
       "189874  Find cheap airline tickets & deals on flights ...  \n",
       "189875  What is a wrap-around mortgage, and who is it ...  \n",
       "189876  Katie The name Katie is a baby girl name. Mean...  \n",
       "\n",
       "[189877 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_passages_top1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "decreased-jamaica",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "passage_dict = {}\n",
    "for idx, row in candidate_passages_top1000.iterrows():\n",
    "    pid = row['pid']\n",
    "    passage = preprocessing(row['passage'])\n",
    "    if pid not in passage_dict:\n",
    "        passage_dict[pid] = passage\n",
    "#         passage_dict[pid] = None\n",
    "#     passage_dict[pid] = passage\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pleased-phase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182469"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(passage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "waiting-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "# term_frequency = frequency_dict[term].frequency if term in frequency_dict else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "covered-guitar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5889367"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "portuguese-sussex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172464"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_no_dup = set(tokens)\n",
    "len(tokens_no_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "gentle-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rna\n",
      "definition\n",
      "along\n",
      "examples\n",
      "type\n",
      "molecules\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "passage = passage_dict[7130104]\n",
    "freqDist = nltk.FreqDist(passage)\n",
    "passage\n",
    "freqDist\n",
    "for check in freqDist:\n",
    "    print(check)\n",
    "\n",
    "if 'rna' in freqDist:\n",
    "    print(freqDist['rna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "incorrect-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_vocabulary(data):\n",
    "#     tokens = []\n",
    "#     for token_list in data.values():\n",
    "#         tokens = tokens + token_list\n",
    "# #     print(\"tokens:\", tokens)\n",
    "#     fdist = nltk.FreqDist(tokens)\n",
    "# #     print(\"fdist:\", fdist.items())\n",
    "#     return list(fdist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = get_vocabulary(passage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for token in tokens_no_dup:\n",
    "    for pid, passage in passage_dict.items():\n",
    "        freqDist = nltk.FreqDist(passage)\n",
    "        if token in freqDist:\n",
    "            inverted_index.setdefault(token, [])\n",
    "            inverted_index[token].append((pid, freqDist[token]))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "refined-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15424"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-valley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
